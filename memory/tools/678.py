import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
from sklearn.cluster import DBSCAN
import seaborn as sns

class GPSParameterAnalyzer:
    """GPSåƒæ•¸åˆ†æå™¨ï¼šè‡ªå‹•è¨ˆç®—optimal spatial_radiuså’Œspatial_threshold"""
    
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.data = pd.read_csv(csv_path)
        self.analysis_results = {}
        
    def analyze_gps_distribution(self):
        """åˆ†æGPSæ•¸æ“šåˆ†ä½ˆ"""
        print("ğŸ” GPSæ•¸æ“šåˆ†æ")
        print("=" * 50)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ­£è¦åŒ–æ¬„ä½
        has_normalized = 'lat_norm' in self.data.columns and 'long_norm' in self.data.columns
        
        if has_normalized:
            print("âœ… ç™¼ç¾æ­£è¦åŒ–GPSæ•¸æ“š")
            lat_col, long_col = 'lat_norm', 'long_norm'
            lat_data = self.data[lat_col].dropna()
            long_data = self.data[long_col].dropna()
        else:
            print("ğŸ“ ä½¿ç”¨åŸå§‹GPSæ•¸æ“š")
            lat_col, long_col = 'lat', 'long'
            lat_data = self.data[lat_col].dropna()
            long_data = self.data[long_col].dropna()
        
        # åŸºæœ¬çµ±è¨ˆ
        stats = {
            'total_records': len(self.data),
            'valid_gps_records': len(lat_data),
            'lat_min': lat_data.min(),
            'lat_max': lat_data.max(),
            'lat_range': lat_data.max() - lat_data.min(),
            'lat_std': lat_data.std(),
            'long_min': long_data.min(),
            'long_max': long_data.max(),
            'long_range': long_data.max() - long_data.min(),
            'long_std': long_data.std(),
            'lat_col': lat_col,
            'long_col': long_col
        }
        
        self.analysis_results['basic_stats'] = stats
        
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  ç¸½è¨˜éŒ„æ•¸: {stats['total_records']}")
        print(f"  æœ‰æ•ˆGPSè¨˜éŒ„: {stats['valid_gps_records']}")
        print(f"  {lat_col}ç¯„åœ: [{stats['lat_min']:.8f}, {stats['lat_max']:.8f}] (è·¨åº¦: {stats['lat_range']:.8f})")
        print(f"  {long_col}ç¯„åœ: [{stats['long_min']:.8f}, {stats['long_max']:.8f}] (è·¨åº¦: {stats['long_range']:.8f})")
        print(f"  ç·¯åº¦æ¨™æº–å·®: {stats['lat_std']:.8f}")
        print(f"  ç¶“åº¦æ¨™æº–å·®: {stats['long_std']:.8f}")
        
        return stats
    
    def calculate_distance_statistics(self, sample_size=2000):
        """è¨ˆç®—GPSè·é›¢çµ±è¨ˆ"""
        print(f"\nğŸ“ GPSè·é›¢çµ±è¨ˆåˆ†æ (æ¨£æœ¬æ•¸: {sample_size})")
        print("-" * 40)
        
        stats = self.analysis_results['basic_stats']
        lat_col, long_col = stats['lat_col'], stats['long_col']
        
        # å–æ¨£ä»¥åŠ å¿«è¨ˆç®—
        valid_data = self.data[[lat_col, long_col]].dropna()
        if len(valid_data) > sample_size:
            sample_data = valid_data.sample(n=sample_size, random_state=42)
        else:
            sample_data = valid_data
        
        # è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢çŸ©é™£
        coords = sample_data[[lat_col, long_col]].values
        distances = cdist(coords, coords, metric='euclidean')
        
        # å–ä¸Šä¸‰è§’çŸ©é™£ï¼ˆæ’é™¤å°è§’ç·šå’Œé‡è¤‡ï¼‰
        upper_tri_indices = np.triu_indices_from(distances, k=1)
        distance_values = distances[upper_tri_indices]
        
        # è·é›¢çµ±è¨ˆ
        distance_stats = {
            'min_distance': distance_values.min(),
            'max_distance': distance_values.max(),
            'mean_distance': distance_values.mean(),
            'median_distance': np.median(distance_values),
            'std_distance': distance_values.std(),
            'percentiles': {
                '5%': np.percentile(distance_values, 5),
                '10%': np.percentile(distance_values, 10),
                '25%': np.percentile(distance_values, 25),
                '75%': np.percentile(distance_values, 75),
                '90%': np.percentile(distance_values, 90),
                '95%': np.percentile(distance_values, 95),
                '99%': np.percentile(distance_values, 99)
            },
            'zero_distances': np.sum(distance_values == 0),
            'total_pairs': len(distance_values)
        }
        
        self.analysis_results['distance_stats'] = distance_stats
        
        print(f"  æœ€å°è·é›¢: {distance_stats['min_distance']:.8f}")
        print(f"  æœ€å¤§è·é›¢: {distance_stats['max_distance']:.8f}")
        print(f"  å¹³å‡è·é›¢: {distance_stats['mean_distance']:.8f}")
        print(f"  ä¸­ä½æ•¸è·é›¢: {distance_stats['median_distance']:.8f}")
        print(f"  è·é›¢æ¨™æº–å·®: {distance_stats['std_distance']:.8f}")
        print(f"  é›¶è·é›¢å°æ•¸: {distance_stats['zero_distances']}/{distance_stats['total_pairs']}")
        
        print(f"\n  è·é›¢åˆ†ä½æ•¸:")
        for k, v in distance_stats['percentiles'].items():
            print(f"    {k}: {v:.8f}")
        
        return distance_stats
    
    def find_optimal_spatial_radius(self):
        """å°‹æ‰¾æœ€ä½³spatial_radius (ç”¨æ–¼è¨˜æ†¶åº«)"""
        print(f"\nğŸ§  å°‹æ‰¾æœ€ä½³spatial_radius")
        print("-" * 40)
        
        distance_stats = self.analysis_results['distance_stats']
        
        # spatial_radiuså»ºè­°ç¯„åœï¼šæ‡‰è©²æ¯”æœ€å°éé›¶è·é›¢å°ï¼Œä½†ä¸è¦å¤ªå°
        min_nonzero_dist = distance_stats['min_distance']
        mean_dist = distance_stats['mean_distance']
        
        # å»ºè­°å€¼ï¼š5%åˆ†ä½æ•¸åˆ°10%åˆ†ä½æ•¸ä¹‹é–“
        suggested_radius = distance_stats['percentiles']['5%'] * 0.1
        
        # ç¢ºä¿ä¸æœƒå¤ªå°
        if suggested_radius < 1e-8:
            suggested_radius = 1e-6
        
        # ä¹Ÿä¸è¦å¤ªå¤§
        if suggested_radius > mean_dist * 0.1:
            suggested_radius = mean_dist * 0.1
        
        spatial_radius_analysis = {
            'suggested_radius': suggested_radius,
            'min_nonzero_distance': min_nonzero_dist,
            'reasoning': f"è¨­ç‚º5%åˆ†ä½æ•¸çš„10%ï¼Œç¢ºä¿ç›¸è¿‘ä½ç½®èƒ½èšé¡ä½†ä¸æœƒéåº¦èšåˆ"
        }
        
        self.analysis_results['spatial_radius'] = spatial_radius_analysis
        
        print(f"  å»ºè­°spatial_radius: {suggested_radius:.8f}")
        print(f"  ç†ç”±: {spatial_radius_analysis['reasoning']}")
        
        return suggested_radius
    
    def find_optimal_spatial_threshold(self):
        """å°‹æ‰¾æœ€ä½³spatial_threshold (ç”¨æ–¼å°æ¯”å­¸ç¿’)"""
        print(f"\nğŸ¯ å°‹æ‰¾æœ€ä½³spatial_threshold")
        print("-" * 40)
        
        distance_stats = self.analysis_results['distance_stats']
        
        # spatial_thresholdå»ºè­°ï¼šæ‡‰è©²è®“å¤§éƒ¨åˆ†æ¨£æœ¬å°æˆç‚ºè² æ¨£æœ¬
        # ä½†ä¹Ÿè¦é¿å…æŠŠçœŸæ­£ç›¸è¿‘çš„ä½ç½®å¼·åˆ¶åˆ†é›¢
        
        # å»ºè­°ç¯„åœï¼š10%åˆ°25%åˆ†ä½æ•¸ä¹‹é–“
        p10 = distance_stats['percentiles']['10%']
        p25 = distance_stats['percentiles']['25%']
        
        # é¸æ“‡15%åˆ†ä½æ•¸ä½œç‚ºé–¾å€¼
        suggested_threshold = np.percentile([p10, p25], 30)  # ä»‹æ–¼10%å’Œ25%ä¹‹é–“
        
        # è¨ˆç®—ä½¿ç”¨æ­¤é–¾å€¼æ™‚çš„è² æ¨£æœ¬æ¯”ä¾‹
        sample_data = self.data[[self.analysis_results['basic_stats']['lat_col'], 
                                self.analysis_results['basic_stats']['long_col']]].dropna()
        if len(sample_data) > 500:
            test_sample = sample_data.sample(n=500, random_state=42)
        else:
            test_sample = sample_data
        
        test_coords = test_sample.values
        test_distances = cdist(test_coords, test_coords, metric='euclidean')
        
        # è¨ˆç®—è¶…éé–¾å€¼çš„æ¯”ä¾‹
        upper_tri = np.triu_indices_from(test_distances, k=1)
        test_distance_values = test_distances[upper_tri]
        negative_ratio = np.sum(test_distance_values > suggested_threshold) / len(test_distance_values)
        
        spatial_threshold_analysis = {
            'suggested_threshold': suggested_threshold,
            'negative_sample_ratio': negative_ratio,
            'total_test_pairs': len(test_distance_values),
            'negative_pairs': np.sum(test_distance_values > suggested_threshold),
            'reasoning': f"é¸æ“‡è®“{negative_ratio:.1%}çš„æ¨£æœ¬å°æˆç‚ºè² æ¨£æœ¬ï¼Œå¹³è¡¡å°æ¯”å­¸ç¿’æ•ˆæœ"
        }
        
        self.analysis_results['spatial_threshold'] = spatial_threshold_analysis
        
        print(f"  å»ºè­°spatial_threshold: {suggested_threshold:.8f}")
        print(f"  è² æ¨£æœ¬æ¯”ä¾‹: {negative_ratio:.1%}")
        print(f"  è² æ¨£æœ¬å°æ•¸: {spatial_threshold_analysis['negative_pairs']}/{spatial_threshold_analysis['total_test_pairs']}")
        print(f"  ç†ç”±: {spatial_threshold_analysis['reasoning']}")
        
        return suggested_threshold
    
    def test_dbscan_clustering(self, eps_candidates=None):
        """æ¸¬è©¦DBSCANèšé¡æ•ˆæœ"""
        print(f"\nğŸ”¬ DBSCANèšé¡æ¸¬è©¦")
        print("-" * 40)
        
        if eps_candidates is None:
            distance_stats = self.analysis_results['distance_stats']
            # æ¸¬è©¦ä¸åŒçš„epså€¼
            eps_candidates = [
                distance_stats['percentiles']['5%'] * 0.1,
                distance_stats['percentiles']['5%'] * 0.5,
                distance_stats['percentiles']['10%'],
                distance_stats['percentiles']['25%'],
                distance_stats['mean_distance'] * 0.1
            ]
        
        lat_col = self.analysis_results['basic_stats']['lat_col']
        long_col = self.analysis_results['basic_stats']['long_col']
        
        coords = self.data[[lat_col, long_col]].dropna().values
        
        clustering_results = []
        
        for eps in eps_candidates:
            dbscan = DBSCAN(eps=eps, min_samples=2)
            labels = dbscan.fit_predict(coords)
            
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            n_noise = list(labels).count(-1)
            
            result = {
                'eps': eps,
                'n_clusters': n_clusters,
                'n_noise': n_noise,
                'noise_ratio': n_noise / len(labels),
                'avg_cluster_size': (len(labels) - n_noise) / max(n_clusters, 1)
            }
            clustering_results.append(result)
            
            print(f"  eps={eps:.8f}: {n_clusters}å€‹èšé¡, {n_noise}å€‹å™ªè²é» ({result['noise_ratio']:.1%})")
        
        self.analysis_results['clustering_results'] = clustering_results
        
        # æ¨è–¦æœ€ä½³epså€¼
        best_result = min(clustering_results, 
                         key=lambda x: abs(x['noise_ratio'] - 0.1))  # ç›®æ¨™å™ªè²æ¯”ä¾‹10%
        
        print(f"\n  æ¨è–¦eps (spatial_radius): {best_result['eps']:.8f}")
        print(f"  å°‡ç”¢ç”Ÿ {best_result['n_clusters']} å€‹èšé¡ï¼Œå™ªè²æ¯”ä¾‹ {best_result['noise_ratio']:.1%}")
        
        return best_result['eps']
    
    def generate_recommendations(self):
        """ç”Ÿæˆæœ€çµ‚å»ºè­°"""
        print(f"\nğŸ¯ æœ€çµ‚å»ºè­°")
        print("=" * 50)
        
        spatial_radius = self.analysis_results['spatial_radius']['suggested_radius']
        spatial_threshold = self.analysis_results['spatial_threshold']['suggested_threshold']
        
        print(f"æ¨è–¦åƒæ•¸è¨­ç½®:")
        print(f"  --spatial-radius {spatial_radius:.8f}")
        print(f"  --spatial-threshold {spatial_threshold:.8f}")
        
        print(f"\nå‘½ä»¤è¡Œç¯„ä¾‹:")
        print(f"python -m tools.your_script \\")
        print(f"  [å…¶ä»–åƒæ•¸] \\")
        print(f"  --spatial-radius {spatial_radius:.8f} \\")
        print(f"  --spatial-threshold {spatial_threshold:.8f} \\")
        print(f"  --contrastive-weight 0.7")
        
        # ç”Ÿæˆä¸åŒscenarioçš„å»ºè­°
        print(f"\nğŸ“‹ ä¸åŒå ´æ™¯å»ºè­°:")
        
        print(f"ğŸ¯ ä¿å®ˆè¨­ç½® (æ›´å°‘è² æ¨£æœ¬):")
        conservative_threshold = spatial_threshold * 2
        print(f"  --spatial-threshold {conservative_threshold:.8f}")
        
        print(f"ğŸš€ æ¿€é€²è¨­ç½® (æ›´å¤šè² æ¨£æœ¬):")
        aggressive_threshold = spatial_threshold * 0.5
        print(f"  --spatial-threshold {aggressive_threshold:.8f}")
        
        print(f"ğŸ§  è¨˜æ†¶åº«å„ªåŒ–:")
        memory_radius = spatial_radius * 0.5
        print(f"  --spatial-radius {memory_radius:.8f}")
        
        return {
            'spatial_radius': spatial_radius,
            'spatial_threshold': spatial_threshold,
            'conservative_threshold': conservative_threshold,
            'aggressive_threshold': aggressive_threshold,
            'memory_radius': memory_radius
        }
    
    def plot_distance_distribution(self, save_path=None):
        """ç¹ªè£½è·é›¢åˆ†ä½ˆåœ–"""
        if 'distance_stats' not in self.analysis_results:
            print("è«‹å…ˆåŸ·è¡Œ calculate_distance_statistics()")
            return
        
        # é‡æ–°è¨ˆç®—è·é›¢ç”¨æ–¼ç¹ªåœ–
        lat_col = self.analysis_results['basic_stats']['lat_col']
        long_col = self.analysis_results['basic_stats']['long_col']
        
        sample_data = self.data[[lat_col, long_col]].dropna().sample(n=min(1000, len(self.data)), random_state=42)
        coords = sample_data.values
        distances = cdist(coords, coords, metric='euclidean')
        upper_tri_indices = np.triu_indices_from(distances, k=1)
        distance_values = distances[upper_tri_indices]
        
        plt.figure(figsize=(12, 8))
        
        # å­åœ–1: è·é›¢ç›´æ–¹åœ–
        plt.subplot(2, 2, 1)
        plt.hist(distance_values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.axvline(self.analysis_results['spatial_threshold']['suggested_threshold'], 
                   color='red', linestyle='--', label=f'å»ºè­°threshold: {self.analysis_results["spatial_threshold"]["suggested_threshold"]:.6f}')
        plt.axvline(self.analysis_results['spatial_radius']['suggested_radius'], 
                   color='green', linestyle='--', label=f'å»ºè­°radius: {self.analysis_results["spatial_radius"]["suggested_radius"]:.6f}')
        plt.xlabel('GPSè·é›¢')
        plt.ylabel('é »ç‡')
        plt.title('GPSè·é›¢åˆ†ä½ˆ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­åœ–2: ç´¯ç©åˆ†ä½ˆ
        plt.subplot(2, 2, 2)
        sorted_distances = np.sort(distance_values)
        cumulative = np.arange(1, len(sorted_distances) + 1) / len(sorted_distances)
        plt.plot(sorted_distances, cumulative, 'b-', linewidth=2)
        plt.axvline(self.analysis_results['spatial_threshold']['suggested_threshold'], 
                   color='red', linestyle='--', label=f'å»ºè­°threshold')
        plt.axvline(self.analysis_results['spatial_radius']['suggested_radius'], 
                   color='green', linestyle='--', label=f'å»ºè­°radius')
        plt.xlabel('GPSè·é›¢')
        plt.ylabel('ç´¯ç©æ©Ÿç‡')
        plt.title('GPSè·é›¢ç´¯ç©åˆ†ä½ˆ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­åœ–3: å°æ•¸å°ºåº¦ç›´æ–¹åœ–
        plt.subplot(2, 2, 3)
        plt.hist(distance_values[distance_values > 0], bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
        plt.yscale('log')
        plt.xlabel('GPSè·é›¢')
        plt.ylabel('é »ç‡ (å°æ•¸å°ºåº¦)')
        plt.title('GPSè·é›¢åˆ†ä½ˆ (å°æ•¸å°ºåº¦)')
        plt.grid(True, alpha=0.3)
        
        # å­åœ–4: ç®±å‹åœ–
        plt.subplot(2, 2, 4)
        plt.boxplot(distance_values, vert=True, patch_artist=True,
                   boxprops=dict(facecolor='lightgreen', alpha=0.7))
        plt.ylabel('GPSè·é›¢')
        plt.title('GPSè·é›¢ç®±å‹åœ–')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"åœ–è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def run_complete_analysis(self):
        """åŸ·è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å•Ÿå‹•GPSåƒæ•¸å®Œæ•´åˆ†æ")
        print("=" * 60)
        
        # 1. åŸºæœ¬åˆ†ä½ˆåˆ†æ
        self.analyze_gps_distribution()
        
        # 2. è·é›¢çµ±è¨ˆåˆ†æ
        self.calculate_distance_statistics()
        
        # 3. å°‹æ‰¾æœ€ä½³spatial_radius
        self.find_optimal_spatial_radius()
        
        # 4. å°‹æ‰¾æœ€ä½³spatial_threshold
        self.find_optimal_spatial_threshold()
        
        # 5. DBSCANèšé¡æ¸¬è©¦
        self.test_dbscan_clustering()
        
        # 6. ç”Ÿæˆæœ€çµ‚å»ºè­°
        recommendations = self.generate_recommendations()
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        
        return recommendations


# ä½¿ç”¨ç¯„ä¾‹
def analyze_your_gps_data(csv_path):
    """åˆ†ææ‚¨çš„GPSæ•¸æ“š"""
    analyzer = GPSParameterAnalyzer(csv_path)
    
    # åŸ·è¡Œå®Œæ•´åˆ†æ
    recommendations = analyzer.run_complete_analysis()
    
    # ç¹ªè£½åˆ†ä½ˆåœ–
    try:
        analyzer.plot_distance_distribution(save_path='gps_distance_analysis.png')
    except Exception as e:
        print(f"ç¹ªåœ–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return recommendations, analyzer

if __name__ == "__main__":
    # ä½¿ç”¨æ‚¨çš„CSVæª”æ¡ˆ
    csv_file = "YOUR_DATA_norm.csv"
    
    print("ğŸ” åˆ†æGPSæ•¸æ“šä»¥æ‰¾åˆ°æœ€ä½³åƒæ•¸...")
    recommendations, analyzer = analyze_your_gps_data(csv_file)
    
    print(f"\nğŸ¯ å¿«é€Ÿè¨­ç½®:")
    print(f"--spatial-radius {recommendations['spatial_radius']:.8f}")
    print(f"--spatial-threshold {recommendations['spatial_threshold']:.8f}")