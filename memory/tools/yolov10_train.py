import os
import pandas as pd
from argparse import ArgumentParser, Namespace
from typing import Dict, Any

import torch
import torch.nn.functional as F
from rich import print
from rich.progress import Progress
from rich.table import Table

import engine.transform as transform
from engine.category import Category
from engine.dataloading import ImgAnnDataset
from engine.logger import Logger
from engine.metric import Metrics
from engine.visualizer import IdMapVisualizer, ImgSaver
from engine.yolov10 import YOLOv10MemoryEnhancedGeoSegformer, create_yolov10_memory_enhanced_geo_segformer


class ContrastiveLoss(torch.nn.Module):
    """å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œç”¨äºå¯¹é½å›¾åƒå’Œ GPS ç‰¹å¾"""
    def __init__(self, temperature: float = 0.07):
        super().__init__()
        self.temperature = temperature
        
    def forward(self, image_embeds: torch.Tensor, location_embeds: torch.Tensor) -> torch.Tensor:
        if image_embeds is None or location_embeds is None:
            return torch.tensor(0.0, device=image_embeds.device if image_embeds is not None else 'cpu')
        
        batch_size = image_embeds.shape[0]
        
        if image_embeds.shape != location_embeds.shape:
            return torch.tensor(0.0, device=image_embeds.device)
        
        if torch.isnan(image_embeds).any() or torch.isnan(location_embeds).any():
            return torch.tensor(0.0, device=image_embeds.device)
        
        # æ­£è§„åŒ–åµŒå…¥
        image_embeds = F.normalize(image_embeds, dim=-1)
        location_embeds = F.normalize(location_embeds, dim=-1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity = torch.matmul(image_embeds, location_embeds.T) / self.temperature
        
        # åˆ›å»ºæ ‡ç­¾ï¼ˆå¯¹è§’çº¿ä¸ºæ­£æ ·æœ¬ï¼‰
        labels = torch.arange(batch_size, device=image_embeds.device)
        
        # åŒå‘å¯¹æ¯”æŸå¤±
        loss_i2l = F.cross_entropy(similarity, labels)
        loss_l2i = F.cross_entropy(similarity.T, labels)
        
        final_loss = (loss_i2l + loss_l2i) / 2
        
        if torch.isnan(final_loss):
            return torch.tensor(0.0, device=image_embeds.device)
        
        return final_loss


class MemoryAwareContrastiveLoss(torch.nn.Module):
    """è®°å¿†æ„ŸçŸ¥çš„å¯¹æ¯”å­¦ä¹ æŸå¤±"""
    def __init__(self, temperature: float = 0.07, spatial_threshold: float = 0.0001):
        super().__init__()
        self.temperature = temperature
        self.spatial_threshold = spatial_threshold
        
    def forward(self, image_embeds: torch.Tensor, location_embeds: torch.Tensor, gps_coords: torch.Tensor) -> torch.Tensor:
        if image_embeds is None or location_embeds is None:
            return torch.tensor(0.0, device=image_embeds.device if image_embeds is not None else 'cpu')
        
        batch_size = image_embeds.shape[0]
        
        # è®¡ç®—GPSè·ç¦»çŸ©é˜µ
        gps_distances = torch.cdist(gps_coords, gps_coords)
        
        # æ­£è§„åŒ–åµŒå…¥
        image_embeds = F.normalize(image_embeds, dim=-1)
        location_embeds = F.normalize(location_embeds, dim=-1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity = torch.matmul(image_embeds, location_embeds.T) / self.temperature
        
        total_loss = 0
        valid_samples = 0
        
        for i in range(batch_size):
            # æ‰¾åˆ°è·ç¦»è¾ƒè¿œçš„è´Ÿæ ·æœ¬
            far_mask = gps_distances[i] > self.spatial_threshold
            neg_indices = torch.where(far_mask)[0]
            
            if len(neg_indices) > 0:
                # æ­£æ ·æœ¬ï¼ˆè‡ªå·±ï¼‰
                pos_sim = similarity[i, i]
                
                # è´Ÿæ ·æœ¬ï¼ˆè·ç¦»è¾ƒè¿œçš„ä½ç½®ï¼‰
                neg_sims = similarity[i, neg_indices]
                
                # å¯¹æ¯”æŸå¤±
                logits = torch.cat([pos_sim.unsqueeze(0), neg_sims])
                labels = torch.zeros(1, dtype=torch.long, device=image_embeds.device)
                loss = F.cross_entropy(logits.unsqueeze(0), labels)
                
                total_loss += loss
                valid_samples += 1
        
        return total_loss / max(valid_samples, 1)


class MemoryEnhancedGeoSegDataset(ImgAnnDataset):
    """è®°å¿†å¢å¼ºç‰ˆæ•°æ®é›†"""
    def __init__(
        self,
        transforms: list,
        img_dir: str,
        ann_dir: str,
        gps_csv: str,
        max_len: int = None,
    ):
        super().__init__(transforms, img_dir, ann_dir, max_len)
        
        # è½½å…¥ GPS æ•°æ®
        self.gps_data = pd.read_csv(gps_csv)
        
        # åˆ›å»ºæ–‡ä»¶ååˆ° GPS çš„æ˜ å°„
        self.filename_to_gps = {}
        for _, row in self.gps_data.iterrows():
            filename = os.path.splitext(row['filename'])[0]
            self.filename_to_gps[filename] = [row['lat'], row['long']]
        
        print(f"âœ… Loaded GPS data for {len(self.filename_to_gps)} images")
        
        # åˆ†æGPSæ•°æ®åˆ†å¸ƒ
        self.analyze_gps_distribution()
    
    def analyze_gps_distribution(self):
        """åˆ†æGPSæ•°æ®åˆ†å¸ƒ"""
        lats = [coords[0] for coords in self.filename_to_gps.values()]
        lons = [coords[1] for coords in self.filename_to_gps.values()]
        
        print(f"ğŸ“Š GPSæ•°æ®åˆ†æ:")
        print(f"  çº¬åº¦èŒƒå›´: [{min(lats):.6f}, {max(lats):.6f}] (èŒƒå›´: {max(lats)-min(lats):.6f})")
        print(f"  ç»åº¦èŒƒå›´: [{min(lons):.6f}, {max(lons):.6f}] (èŒƒå›´: {max(lons)-min(lons):.6f})")
        
        # è®¡ç®—é‡å¤ä½ç½®
        unique_positions = set()
        duplicate_count = 0
        for coords in self.filename_to_gps.values():
            coord_str = f"{coords[0]:.7f},{coords[1]:.7f}"
            if coord_str in unique_positions:
                duplicate_count += 1
            else:
                unique_positions.add(coord_str)
        
        duplicate_rate = duplicate_count / len(self.filename_to_gps) * 100
        print(f"  å”¯ä¸€ä½ç½®æ•°: {len(unique_positions)}")
        print(f"  é‡å¤ä½ç½®ç‡: {duplicate_rate:.2f}%")
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        # è·å–åŸå§‹æ•°æ®
        data = super().__getitem__(idx)
        
        # ä»è·¯å¾„ä¸­æå–æ–‡ä»¶å
        img_path = self.img_ann_paths[idx][0]
        filename = os.path.splitext(os.path.basename(img_path))[0]
        
        # æ·»åŠ  GPS æ•°æ®å’Œæ–‡ä»¶å
        if filename in self.filename_to_gps:
            gps_coords = self.filename_to_gps[filename]
            data['gps'] = torch.tensor(gps_coords, dtype=torch.float32)
        else:
            print(f"âš ï¸ Warning: No GPS data found for {filename}")
            data['gps'] = torch.zeros(2, dtype=torch.float32)
        
        # æ·»åŠ æ–‡ä»¶åç”¨äºè·Ÿè¸ª
        data['filename'] = filename
        
        return data
    

def setup_gps_normalization(train_gps_csv: str, val_gps_csv: str, method: str = "minmax"):
    """è®¾ç½®GPSæ­£è§„åŒ–"""
    
    # åˆå¹¶è®­ç»ƒå’ŒéªŒè¯é›†è®¡ç®—å…¨å±€ç»Ÿè®¡
    train_gps = pd.read_csv(train_gps_csv)
    val_gps = pd.read_csv(val_gps_csv)
    all_gps = pd.concat([train_gps, val_gps], ignore_index=True)
    
    if method == "minmax":
        lat_min = all_gps['lat'].min()
        lat_max = all_gps['lat'].max()
        lon_min = all_gps['long'].min()
        lon_max = all_gps['long'].max()
        
        # æ·»åŠ å°é‡paddingé¿å…è¾¹ç•Œé—®é¢˜
        lat_range = lat_max - lat_min
        lon_range = lon_max - lon_min
        padding = 0.01  # 1%çš„padding
        
        lat_min -= lat_range * padding
        lat_max += lat_range * padding
        lon_min -= lon_range * padding
        lon_max += lon_range * padding
        
        return transform.GPSNormalize(
            lat_range=(lat_min, lat_max),
            lon_range=(lon_min, lon_max)
        )
    else:
        raise ValueError(f"Method {method} not implemented yet")


def parse_args() -> Namespace:
    parser = ArgumentParser(description="YOLOv10 Memory-Enhanced GeoSegformer Training")
    
    # æ•°æ®è·¯å¾„
    parser.add_argument("train_img_dir", type=str)
    parser.add_argument("train_ann_dir", type=str)
    parser.add_argument("val_img_dir", type=str)  
    parser.add_argument("val_ann_dir", type=str)
    parser.add_argument("category_csv", type=str)
    parser.add_argument("train_gps_csv", type=str)
    parser.add_argument("val_gps_csv", type=str)
    parser.add_argument("max_epochs", type=int)
    parser.add_argument("logdir", type=str)
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--yolo-model", type=str, default="yolov10n", 
                       choices=["yolov10n", "yolov10s", "yolov10m", "yolov10l", "yolov10x"],
                       help="YOLOv10 model variant")
    parser.add_argument("--feature-dim", type=int, default=512)
    parser.add_argument("--fusion-method", type=str, default="attention", 
                       choices=["add", "concat", "attention"])
    parser.add_argument("--freeze-backbone", action="store_true", 
                       help="Freeze YOLOv10 backbone weights")
    
    # è®°å¿†åº“å‚æ•°
    parser.add_argument("--memory-size", type=int, default=20, help="Memory size per location")
    parser.add_argument("--spatial-radius", type=float, default=0.00005, help="Spatial radius for memory")
    parser.add_argument("--gps-norm-method", type=str, default="minmax", 
                       choices=["minmax", "zscore"], help="GPS normalization method")
    
    # æŸå¤±æƒé‡
    parser.add_argument("--seg-weight", type=float, default=1.0)
    parser.add_argument("--contrastive-weight", type=float, default=0.05)
    parser.add_argument("--temperature", type=float, default=0.07)
    parser.add_argument("--spatial-threshold", type=float, default=0.0001)
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--save-interval", type=int, default=1)
    parser.add_argument("--checkpoint-interval", type=int, default=10)
    parser.add_argument("--val-interval", type=int, default=1)
    parser.add_argument("--batch-size", type=int, default=4, help="Batch size (YOLOv10 may need smaller)")
    parser.add_argument("--num-workers", type=int, default=4)
    parser.add_argument("--train-max-len", type=int, default=None)
    parser.add_argument("--val-max-len", type=int, default=None)
    parser.add_argument("--pin-memory", action="store_true", default=True)
    parser.add_argument("--resume", type=int, default=0)
    
    # è®°å¿†åº“ç›¸å…³
    parser.add_argument("--memory-warmup-epochs", type=int, default=2)
    parser.add_argument("--save-memory-stats", action="store_true")
    
    # YOLOv10ç‰¹å®šå‚æ•°
    parser.add_argument("--input-size", type=int, default=640, 
                       help="Input image size (YOLOv10 typically uses 640)")
    
    return parser.parse_args()


def main(args: Namespace):
    
    # YOLOv10é€šå¸¸ä½¿ç”¨640x640è¾“å…¥
    image_size = args.input_size, args.input_size  # H x W
    crop_size = 512, 512  # å¯ä»¥ä¿æŒ512ç”¨äºè®­ç»ƒ
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # è½½å…¥ç±»åˆ«å®šä¹‰
    categories = Category.load(args.category_csv)
    num_categories = Category.get_num_categories(categories)
    
    print(f"ğŸš€ YOLOv10è®°å¿†å¢å¼ºç‰ˆ GeoSegformer è®­ç»ƒé…ç½®:")
    print(f"  YOLOæ¨¡å‹: {args.yolo_model}")
    print(f"  è¾“å…¥å°ºå¯¸: {args.input_size}x{args.input_size}")
    print(f"  ç‰¹å¾ç»´åº¦: {args.feature_dim}")
    print(f"  è®°å¿†åº“å¤§å°: {args.memory_size}")
    print(f"  ç©ºé—´åŠå¾„: {args.spatial_radius}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  å†»ç»“backbone: {args.freeze_backbone}")
    
    gps_normalizer = setup_gps_normalization(
        args.train_gps_csv, 
        args.val_gps_csv,
        method=getattr(args, 'gps_norm_method', 'minmax')
    )
    
    # åˆ›å»ºä¿®å¤ç‰ˆå®˜æ–¹YOLOv10è®°å¿†å¢å¼ºæ¨¡å‹
    memory_save_path = os.path.join(args.logdir, "yolov10_fixed_memory_stats.json") if args.save_memory_stats else None
    
    model = create_yolov10_memory_enhanced_geo_segformer(
        num_classes=num_categories,
        yolo_model=args.yolo_model,
        feature_dim=args.feature_dim,
        fusion_method=args.fusion_method,
        memory_size=args.memory_size,
        spatial_radius=args.spatial_radius,
        memory_save_path=memory_save_path,
        freeze_backbone=args.freeze_backbone
    ).to(device)
    
    print(f"âœ… åˆ›å»ºä¿®å¤ç‰ˆå®˜æ–¹YOLOv10è®°å¿†å¢å¼ºæ¨¡å‹ï¼Œå‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # æ•°æ®å˜æ¢ - é’ˆå¯¹YOLOv10ä¼˜åŒ–
    train_transforms = [
        transform.LoadImg(),
        transform.LoadAnn(),
        gps_normalizer,
        transform.RandomResizeCrop(image_size, (0.8, 2), crop_size),
        transform.ColorJitter(0.3, 0.3, 0.3),
        transform.Normalize(),
    ]
    
    val_transforms = [
        transform.LoadImg(),
        transform.LoadAnn(),
        gps_normalizer,
        transform.Resize(image_size),
        transform.Normalize(),
    ]
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = MemoryEnhancedGeoSegDataset(
        transforms=train_transforms,
        img_dir=args.train_img_dir,
        ann_dir=args.train_ann_dir,
        gps_csv=args.train_gps_csv,
        max_len=args.train_max_len,
    )
    
    val_dataset = MemoryEnhancedGeoSegDataset(
        transforms=val_transforms,
        img_dir=args.val_img_dir,
        ann_dir=args.val_ann_dir,
        gps_csv=args.val_gps_csv,
        max_len=args.val_max_len,
    )
    
    # æ•°æ®åŠ è½½å™¨
    train_dataloader = train_dataset.get_loader(
        batch_size=args.batch_size,
        pin_memory=args.pin_memory,
        num_workers=args.num_workers,
        shuffle=True,
        drop_last=True,
    )
    
    val_dataloader = val_dataset.get_loader(
        batch_size=1,  # éªŒè¯æ—¶ä½¿ç”¨batch_size=1
        pin_memory=args.pin_memory,
        num_workers=args.num_workers,
    )
    
    # æŸå¤±å‡½æ•°
    seg_criterion = torch.nn.CrossEntropyLoss().to(device)
    contrastive_criterion = MemoryAwareContrastiveLoss(
        temperature=args.temperature,
        spatial_threshold=args.spatial_threshold
    ).to(device)
    
    # è¯„ä¼°æŒ‡æ ‡
    metrics = Metrics(num_categories, nan_to_num=0)
    
    # ä¼˜åŒ–å™¨ - æ”¯æŒå†»ç»“backboneé€‰é¡¹
    if args.freeze_backbone:
        # å¦‚æœå†»ç»“backboneï¼Œåªè®­ç»ƒå…¶ä»–éƒ¨åˆ†
        trainable_params = [
            {"params": model.location_encoder.parameters(), "lr": 3e-4},
            {"params": model.memory_fusion.parameters(), "lr": 6e-4},
            {"params": model.memory_attention.parameters(), "lr": 6e-4},
            {"params": model.cross_modal_fusion.parameters(), "lr": 6e-4},
            {"params": model.segmentation_head.parameters(), "lr": 6e-4},
            {"params": model.contrastive_proj.parameters(), "lr": 6e-4},
        ]
        print("ğŸ”’ å®˜æ–¹YOLOv10 Backboneå·²å†»ç»“ï¼Œåªè®­ç»ƒå…¶ä»–ç»„ä»¶")
    else:
        # è®­ç»ƒæ‰€æœ‰å‚æ•°ï¼Œä½†ç»™YOLOv10 backboneè¾ƒä½çš„å­¦ä¹ ç‡
        trainable_params = [
            {"params": model.image_encoder.parameters(), "lr": 1e-5},  # å®˜æ–¹æƒé‡ç”¨å¾ˆä½çš„å­¦ä¹ ç‡
            {"params": model.location_encoder.parameters(), "lr": 3e-4},
            {"params": model.memory_fusion.parameters(), "lr": 6e-4},
            {"params": model.memory_attention.parameters(), "lr": 6e-4},
            {"params": model.cross_modal_fusion.parameters(), "lr": 6e-4},
            {"params": model.segmentation_head.parameters(), "lr": 6e-4},
            {"params": model.contrastive_proj.parameters(), "lr": 6e-4},
        ]
        print("ğŸ”„ å¾®è°ƒå®˜æ–¹YOLOv10æƒé‡ + è®­ç»ƒå…¶ä»–ç»„ä»¶")
    
    optimizer = torch.optim.AdamW(trainable_params, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(
        optimizer, 1e-4, 1, len(train_dataloader) * args.memory_warmup_epochs
    )
    poly_scheduler = torch.optim.lr_scheduler.PolynomialLR(
        optimizer, args.max_epochs, 1e-6
    )
    
    # æ£€æŸ¥ç‚¹æ¢å¤
    if args.resume:
        checkpoint = torch.load(
            os.path.join(args.logdir, f"checkpoint_{args.resume}.pth")
        )
        model.load_state_dict(checkpoint["model"])
        optimizer.load_state_dict(checkpoint["optimizer"])
        start_epoch = args.resume + 1
        print(f"âœ… ä»epoch {args.resume}æ¢å¤è®­ç»ƒ")
    else:
        start_epoch = 1
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    if not args.resume and os.path.exists(args.logdir):
        raise FileExistsError(
            f"{args.logdir} already exists. Please specify a different logdir or resume a checkpoint."
        )
    
    os.makedirs(args.logdir, exist_ok=True)
    logger = Logger(args.logdir)
    img_saver = ImgSaver(args.logdir, IdMapVisualizer(categories))
    
    # è®­ç»ƒå¾ªç¯
    with Progress() as prog:
        whole_task = prog.add_task("YOLOv10 Memory-Enhanced Training", total=args.max_epochs)
        
        for e in range(start_epoch, args.max_epochs + 1):
            train_task = prog.add_task(f"Train - {e}", total=len(train_dataloader))
            
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_seg_loss = 0
            train_contrastive_loss = 0
            train_total_loss = 0
            train_memory_weight = 0
            
            is_warmup = e <= args.memory_warmup_epochs
            
            for batch_idx, data in enumerate(train_dataloader):
                img = data["img"].to(device)
                ann = data["ann"].to(device)[:, 0, :, :]
                gps = data["gps"].to(device)
                
                optimizer.zero_grad()
                
                # å‰å‘ä¼ æ’­
                outputs = model(img, gps, return_embeddings=True, update_memory=True)
                
                # åˆ†å‰²æŸå¤±
                seg_loss = seg_criterion(outputs['segmentation_logits'], ann)
                
                # è®°å¿†æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ æŸå¤±
                contrastive_loss = contrastive_criterion(
                    outputs['image_embeddings'], 
                    outputs['location_embeddings'],
                    gps
                )
                
                # æ€»æŸå¤±ï¼ˆè®°å¿†é¢„çƒ­æœŸé—´å‡å°‘å¯¹æ¯”å­¦ä¹ æƒé‡ï¼‰
                contrastive_weight = args.contrastive_weight * (0.1 if is_warmup else 1.0)
                total_loss = (args.seg_weight * seg_loss + 
                             contrastive_weight * contrastive_loss)
                
                # åå‘ä¼ æ’­
                total_loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                if is_warmup:
                    warmup_scheduler.step()
                
                # è®°å½•æŸå¤±
                train_seg_loss += seg_loss.item()
                train_contrastive_loss += contrastive_loss if isinstance(contrastive_loss, float) else contrastive_loss.item()
                train_total_loss += total_loss.item()
                train_memory_weight += outputs.get('memory_weight', 0)
                
                # å®šæœŸè¾“å‡ºè®°å¿†åº“ç»Ÿè®¡
                if batch_idx % 50 == 0:
                    memory_stats = model.get_memory_stats()
                    logger.info("Memory", 
                               f"Locations: {memory_stats['total_locations']}, "
                               f"Memories: {memory_stats['total_memories']}, "
                               f"Hit Rate: {memory_stats['hit_rate']:.3f}")
                
                prog.update(train_task, advance=1)
            
            # è®¡ç®—å¹³å‡å€¼
            train_seg_loss /= len(train_dataloader)
            train_contrastive_loss /= len(train_dataloader)
            train_total_loss /= len(train_dataloader)
            train_memory_weight /= len(train_dataloader)
            
            # è®°å½•è®­ç»ƒç»“æœ
            logger.info("TrainLoop", f"Total Loss: {train_total_loss:.5f}")
            logger.info("TrainLoop", f"Seg Loss: {train_seg_loss:.5f}")
            logger.info("TrainLoop", f"Contrastive Loss: {train_contrastive_loss:.5f}")
            logger.info("TrainLoop", f"Memory Weight: {train_memory_weight:.4f}")
            
            logger.tb_log("TrainLoop/TotalLoss", train_total_loss, e)
            logger.tb_log("TrainLoop/SegLoss", train_seg_loss, e)
            logger.tb_log("TrainLoop/ContrastiveLoss", train_contrastive_loss, e)
            logger.tb_log("TrainLoop/MemoryWeight", train_memory_weight, e)
            
            # ä¿å­˜è®­ç»ƒæ ·æœ¬
            if e % args.save_interval == 0:
                img_saver.save_img(img, f"train_{e}_img.png")
                img_saver.save_ann(ann, f"train_{e}_ann.png")
                img_saver.save_pred(outputs['segmentation_logits'], f"train_{e}_pred.png")
            
            prog.remove_task(train_task)
            
            # éªŒè¯é˜¶æ®µ
            if e % args.val_interval == 0:
                with torch.no_grad():
                    val_task = prog.add_task(f"Val - {e}", total=len(val_dataloader))
                    model.eval()
                    
                    val_seg_loss = 0
                    val_contrastive_loss = 0
                    val_total_loss = 0
                    val_memory_weight = 0
                    
                    for data in val_dataloader:
                        img = data["img"].to(device)
                        ann = data["ann"].to(device)[:, 0, :, :]
                        gps = data["gps"].to(device)
                        
                        # æ¨ç†ï¼ˆä¸æ›´æ–°è®°å¿†åº“ï¼‰
                        outputs = model(img, gps, return_embeddings=True, update_memory=False)
                        pred = outputs['segmentation_logits']
                        
                        # è®¡ç®—æŸå¤±
                        seg_loss = seg_criterion(pred, ann)
                        contrastive_loss = contrastive_criterion(
                            outputs['image_embeddings'], 
                            outputs['location_embeddings'],
                            gps
                        )
                        total_loss = (args.seg_weight * seg_loss + 
                                     args.contrastive_weight * contrastive_loss)
                        
                        val_seg_loss += seg_loss.item()
                        val_contrastive_loss += contrastive_loss if isinstance(contrastive_loss, float) else contrastive_loss.item()
                        val_total_loss += total_loss.item()
                        val_memory_weight += outputs.get('memory_weight', 0)
                        
                        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                        metrics.compute_and_accum(pred.argmax(1), ann)
                        
                        prog.update(val_task, advance=1)
                    
                    # å¹³å‡æŸå¤±
                    val_seg_loss /= len(val_dataloader)
                    val_contrastive_loss /= len(val_dataloader)
                    val_total_loss /= len(val_dataloader)
                    val_memory_weight /= len(val_dataloader)
                    
                    # ä¿å­˜éªŒè¯æ ·æœ¬
                    img_saver.save_img(img, f"val_{e}_img.png")
                    img_saver.save_ann(ann, f"val_{e}_ann.png")
                    img_saver.save_pred(pred, f"val_{e}_pred.png")
                    
                    # è·å–è¯„ä¼°ç»“æœ
                    result = metrics.get_and_reset()
                    
                    # åˆ›å»ºç»“æœè¡¨æ ¼
                    table = Table()
                    table.add_column("Category")
                    table.add_column("Acc")
                    table.add_column("IoU")
                    table.add_column("Dice")
                    table.add_column("Fscore")
                    table.add_column("Precision")
                    table.add_column("Recall")
                    
                    for cat, acc, iou, dice, fs, pre, rec in zip(
                        categories,
                        result["Acc"],
                        result["IoU"],
                        result["Dice"],
                        result["Fscore"],
                        result["Precision"],
                        result["Recall"],
                    ):
                        table.add_row(
                            cat.name,
                            "{:.5f}".format(acc),
                            "{:.5f}".format(iou),
                            "{:.5f}".format(dice),
                            "{:.5f}".format(fs),
                            "{:.5f}".format(pre),
                            "{:.5f}".format(rec),
                        )
                    
                    # æ·»åŠ å¹³å‡å€¼
                    table.add_row(
                        "Avg.",
                        "{:.5f}".format(result["Acc"].mean()),
                        "{:.5f}".format(result["IoU"].mean()),
                        "{:.5f}".format(result["Dice"].mean()),
                        "{:.5f}".format(result["Fscore"].mean()),
                        "{:.5f}".format(result["Precision"].mean()),
                        "{:.5f}".format(result["Recall"].mean()),
                    )
                    
                    prog.remove_task(val_task)
                    print(table)
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    logger.info("ValLoop", f"Total Loss: {val_total_loss:.5f}")
                    logger.info("ValLoop", f"Seg Loss: {val_seg_loss:.5f}")
                    logger.info("ValLoop", f"Contrastive Loss: {val_contrastive_loss:.5f}")
                    logger.info("ValLoop", f"Memory Weight: {val_memory_weight:.4f}")
                    logger.info("ValLoop", f"mIoU: {result['IoU'].mean():.5f}")
                    
                    logger.tb_log("ValLoop/TotalLoss", val_total_loss, e)
                    logger.tb_log("ValLoop/SegLoss", val_seg_loss, e)
                    logger.tb_log("ValLoop/ContrastiveLoss", val_contrastive_loss, e)
                    logger.tb_log("ValLoop/MemoryWeight", val_memory_weight, e)
                    logger.tb_log("ValLoop/mIoU", result["IoU"].mean(), e)
                    
                    # è®°å¿†åº“ç»Ÿè®¡
                    memory_stats = model.get_memory_stats()
                    logger.info("Memory", f"Final Stats - Locations: {memory_stats['total_locations']}, "
                                         f"Memories: {memory_stats['total_memories']}, "
                                         f"Hit Rate: {memory_stats['hit_rate']:.4f}")
                    
                    logger.tb_log("Memory/TotalLocations", memory_stats['total_locations'], e)
                    logger.tb_log("Memory/TotalMemories", memory_stats['total_memories'], e)
                    logger.tb_log("Memory/HitRate", memory_stats['hit_rate'], e)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if not is_warmup:
                poly_scheduler.step()
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if e % args.checkpoint_interval == 0:
                checkpoint_data = {
                    "model": model.state_dict(),
                    "optimizer": optimizer.state_dict(),
                    "epoch": e,
                    "args": args,
                    "memory_stats": model.get_memory_stats()
                }
                
                if is_warmup:
                    checkpoint_data["warmup_scheduler"] = warmup_scheduler.state_dict()
                else:
                    checkpoint_data["poly_scheduler"] = poly_scheduler.state_dict()
                
                torch.save(
                    checkpoint_data,
                    os.path.join(args.logdir, f"checkpoint_{e}.pth"),
                )
                
                # ä¿å­˜è®°å¿†åº“ç»Ÿè®¡
                if args.save_memory_stats:
                    model.save_memory_bank()
            
            prog.update(whole_task, advance=1)
        
        prog.remove_task(whole_task)
    
    # è®­ç»ƒå®Œæˆåä¿å­˜æœ€ç»ˆè®°å¿†åº“ç»Ÿè®¡
    if args.save_memory_stats:
        model.save_memory_bank()
        
    # æœ€ç»ˆç»Ÿè®¡
    final_memory_stats = model.get_memory_stats()
    print(f"\nğŸ‰ ä¿®å¤ç‰ˆå®˜æ–¹YOLOv10è®°å¿†å¢å¼ºGeoSegformerè®­ç»ƒå®Œæˆï¼")
    print(f"âœ… ä½¿ç”¨äº†å®˜æ–¹YOLOv10é¢„è®­ç»ƒæƒé‡")
    print(f"ğŸ“Š æœ€ç»ˆè®°å¿†åº“ç»Ÿè®¡:")
    print(f"  æ€»ä½ç½®æ•°: {final_memory_stats['total_locations']}")
    print(f"  æ€»è®°å¿†æ•°: {final_memory_stats['total_memories']}")
    print(f"  å‘½ä¸­ç‡: {final_memory_stats['hit_rate']:.4f}")
    print(f"  å¹³å‡æ¯ä½ç½®è®°å¿†æ•°: {final_memory_stats['avg_memories_per_location']:.2f}")


if __name__ == "__main__":
    args = parse_args()
    main(args)
                        